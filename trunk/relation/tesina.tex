% DOCUMENT FORMAT %
\documentclass[twocolumn]{article}

% PACKAGE IMPORT %
\usepackage[latin1]{inputenc} %consente di mettere le accentate direttamente
\usepackage[english,italian]{babel} %sillabazione in italiano
\usepackage{cite}
\usepackage{hyperref}
%%pacchetto per l'inclusione di figure eps
\usepackage[dvips]{graphicx}
\usepackage{epsfig}

\begin{document}
\title{Question Classification and On-Line Alghoritms: Winnow Classifier}
\author{Valerio \& Fabio}
% Remove command to get current date 
\date{\today}
\maketitle

\begin{abstract}
questo lo scrivo alla fine! farò un brevissimo riassunto, niente di particolare.
Però tanto per anticipare quello di cui parliamo è la QC e l'implementazione fatta da noi è 
winnow, un algoritmo on-line.
etc~\ldots\ 
\end{abstract}

\section{Introduction}
Con l'aumento della popolarità e della diffusione del web, e conseguentemente con l'aumento 
dell'informazione testuale sul web, il processamento automatico di informazione testuale scritta in 
linguaggio naturale diviene sempre più importante.\cite{Zhalaing}. A tale fine si usano tecniche di 
Information Retrieval, che sono alla base degli attuali motori di ricerca web: quando un utente ha 
un information need, sottomette una query al motore di ricerca, che produrrà
come output un insieme di documenti che con buona probabilità dovrebbero contenere l'informazione 
necessaria all'utente.

\subsection{Question Answering}
Il Question Answering è una variazione dell'information retrieval (IR): 
mentre l'IR è orientata ai documenti, il QA ricerca specifiche informazioni all'interno dei documenti 
cercando di fornire direttamente la risposta all'information need dell'utente~\cite{WeiLi}. Ed è quindi 
un compito più difficile rispetto all'IR, poiché fornire una risposta precisa e concisa è più complesso 
di produrre un intero documento di testo probabilmente molto lungo.
Un sistema di QA è generalmente costituito da 4 moduli:
\begin{description}
	\item[Question Classifier] ha il compito di classificare la domanda in categorie prestabilite;
	\item[Search Engine] basando sulla categoria prodotta dal modulo precedente, ricerca  i documenti che hanno probabilità più alta di contenere la risposta;
	\item[Text Filter] individua le parti di testo all'interno dei documenti, che potrebbero  contenere la risposta;
	\item[Answer Extractor] deduce la risposta dalle parti di testo individuate dal modulo precedente, e le presenta in linguaggio naturale all'utente del sistema.
\end{description}
% disegno

\subsection{Question Classification}
Il processo di QC ha quindi il compito di assegnare particolari categorie alle domande, basandosi sul tipo 
di risposta che la domanda rappresenta. Per classificare le domande, o più in generale del test, 
è necessario prendere in considerazione due aspetti basilari \cite{brown}:
\begin{itemize}
	\item i tipi delle risposte, le categorie;
	\item un insieme di regole di classificazione.
\end{itemize}
 
\subsubsection{Answer Types}
Definire un proprio insieme di categorie da utilizzare nella question classification è una 
delle soluzioni, ma non sempre la migliore. È possibile utilizzare dei sistemi di categorie già usati in precedenza. 
Il riuso di tali sistemi, oltre a far risparmiare una notevole quantità di tempo, è decisamente utile per 
comparare i propri risultati con altri ottenuti in precedenza. 

I primi sistemi di question classification utilizzavano una suddivisione in un piccolo numero 
di categorie: sei o sette. Recentemente i ricercatori si sono interessati nella costruzione 
di categorie migliori: i sistemi attuali solitamente prevedono 
una divisione in 6-7 categorie a grana grossa, e una successiva suddivisione di ogni categoria in altrettante 
di dettaglio. Tra i tipi di risposte più famosi troviamo:
\begin{itemize}
	\item Xin Li e Dan Roth, che propongono una suddivisione in 50 sotto categorie e 6 macro categorie~\cite{XinLi}:	
	\begin{itemize}
		\item Abbreviation;
		\item Entity;
		\item Description;
		\item Human;
		\item Location;
		\item Numerical Value.
	\end{itemize}
	\item Webclopedia, che usa oltre 140 tipi di risposte, anche chiamati qtargets. Questi sono raggruppati in 
	8 macro categorie~\cite{gerber}:	
	\begin{enumerate}
		\item relational qtargets;
		\item abstract qtargets;
		\item semantic qtargets;
		\item syntactic qtargets;
		\item role qtargets;
		\item slot qtargets;
		\item lexical qtargets;
		\item combinations of other qtargets.
	\end{enumerate}
\end{itemize}

\subsubsection{Classification Strategies}
Esistono diverse strategie/regole di classificazione:

\paragraph{Regular expression and hand-written grammar rules} 
sono le prime tecniche utilizzate per la 
question classification, ma hanno dei grossi limiti, sebbene abbiano avuto successo \cite{brown}:
\begin{itemize}
	\item in primo luogo tali tecniche richiedono molto tempo, poiché sono scritte a mano;
	\item in secondo luogo sono poco evolvibili, con il cambiare delle categorie;
	\item se cambiamo l'insieme delle categorie, tutte le regole devono essere riscritte;
	\item infine sono molto difficili da scrivere, soprattutto quando si usano tante categorie a grana fine.
\end{itemize}
Non è un caso, infatti, che tali sistemi utilizzino meno di dieci categorie.

\paragraph{Machine Learning Algorithm}
L'algoritmo più utilizzato in questo campo è SVM, support vector machine. Un'altra architettura 
molto usata è SNoW~\cite{XinLi}. La precision di tali algoritmi, utlizzando solo le parole delle 
domande, si aggira sul 50\%. Ma si possono utilizzare molte altre feature oltre alle 
semplici parole, come ad esempio: le named entity, head chunk etc~\ldots\ 

\paragraph{Language Modeling} 
Un altro metodo, sempre probabilistico come il machine learning, è il language modeling.
Un modello di linguaggio è creato per ogni classe, a partire da tutte le domande 
appartenenti a quella classe. Dato uno di questi modelli, il nostro obiettivo è
scoprire la probabilità con cui la question sia generata da tale modello. Anche in questo caso 
si possono utilizzare altri insiemi di feature oltre alle semplici parole, come le named entity~\cite{pinto}.


\section{Our Scope: Machine Learning}
Sebbene sia possibile create classificatori con regole euristiche costruite ad hoc~\cite{DBLP:conf/trec/Voorhees01}, tale approccio 
richiede un'enorme quantità di tempo e di noioso lavoro. Per di più un approccio troppo specifico sarebbe poco flessibile ai cambiamenti che si trovano nel dominio di interesse.
Al contrario utilizzando tecniche di machine learning è possibile costruire classificatori che abbiano alte performance e che riescano a gestire migliaia di feature. Oltretutto tale 
approccio è più flessibile e si adatta facilmente a nuove categorie~\cite{Zhang}. Ed è questo 
l'approccio che intendiamo usare per il nostro classificatore.

Le tecniche di machine learning si distinguono in due grandi categorie:
\begin{enumerate}
	\item Off-Line;
	\item On-Line.
\end{enumerate}
Le principali caratteristiche sulle quali si distinguono le due tipolodie sono: tempo di addestramento, flessibilità e conseguentemente per algoritmo.

Un classificatore off-line deve essere addestrato su un insieme di input (training set). Una volta finita la fase di addestramento, è in grado di classificare, ma non più di imparare. Nel caso si voglia far imparare al classificatore nuovi esempi, l'addestramento deve essere iniziato da zero. Questo porterebbe ad una notevole perdita di tempo se il dominio di inferenza, ma anche le categorie utilizzate, cambiassero nel tempo (rendendo il training set precedentemente utilizzato per ``costruire'' il classificatore non più coerente con lo stato attuale). Il tempo di training di un classificatore off-line è solitamente maggiore, se confrontato con un classificatore online, problema affrontato ad esempio anche in~\cite{Habib}.

Al contrario un algoritmo on-line impara sul campo e durante l'addestramento può comunque essere interrogato, questo consente all'addestratore di valutare in continuazione come sta procedendo il lavoro di inferenza del dominio da parte del classificatore.
All'apparenza un classificatore on-line offre più vantaggi ma come spesso accade ai ``pro'' vanno sommati dei ``contro'', che in questo caso ricadono sulle prestazioni del classificatore; un classificatore on-line è tipicamente peggiore di un classificatore off-line.


\subsection{On-Line Algorithm}
Adesso che abbiamo una conoscenza generale delle differenze tra le due classi di algoritmi dobbiamo scegliere quale delle due adottare.

Passiamo quindi all'analisi del dominio di interesse, ovvero la question classification; quest'ultima appartiene ad un dominio intrinsecamente variabile, ambiguo e soprattutto dipendente dal tempo. La QA è variabile nel tempo poiché i significati di una parola sono molteplici e possono variare nel tempo, un caso esemplificativo ed evidente è la parola ``laico'' nella nostra lingua dove fino a pochissimo tempo fa stava ad indicare la non appartenenza all'ecclesia mentre ora ha in pratica preso il significato di ``ateo'' e/o ``agnostico'' (una variazione di significato non indifferente).
Poiché il nostro dominio è fortemente influenzato dalle variazioni del contesto nel quale si trova e poiché l'applicabilità degli algoritmi OffLine è stata studiata approfonditamente in molti lavori %inserire riferimento%
mentre non sono stati approfonditi i comportamenti che hanno gli algoritmi OnLine sul dominio della Question Classification, la scelta ricade sugli questi ultimi.

\subsection{Winnow}
Avendo scelto di utilizzare un algoritmo on-line dobbiamo decidere quale algoritmo di base scegliere per poi testarlo ed adattarlo alle nostre esigenze.
%per ora chiudo veloce ma qui referenze facili%
Tra gli algoritmi on-line la scelta ricade in particolare sull'algoritmo di Winnow.
Questo algoritmo ha delle qualità tra le quali spicca la capacita di non essere influenzato dalla presenza di molti attributi irrilevanti (``winnow è adatto in teoria per problemi con molti attributi irrilevanti''~\cite{Zhang}) e 
``winnow impara linearmente con il numero di feature rilevanti, e solo logaritmicamente con il numero totale di feature. questa proprietà sembra cruciale in problemi nei quali il numero di feature potenziali è vasto 
ma solo poche sono rilevanti''~\cite{snow}.

\section{Winnow Project}
Il progetto di un nostro classificatore avrà la seguente architettura:

\begin{figure}[htb!]
	\centering
	\includegraphics[scale=0.65]{img/WinnowClassifier-Pipeline_No_Example.eps}
	\caption{Winnow Classifier pipeline}
\end{figure}
%DISEGNO CON TRE BLOCCHI
%1)	Nome: Feature Adder (Pre-Processing)
%	Input: Domanda
%	Ouput: Domanda arricchita
%2) Nome: Parsing
%	Input: Domanda
%	Ouput: Vettore/Instance
%1)	Nome: Winnow Classifier
%	Input: Vettore/Instance
%	Ouput: Class
Tre sono i blocchi funzionali presenti messi a cascata fra loro.

Per ora trascuriamo il primo blocco ed immaginiamo che la domanda venga processata dal Feature Adder. La domanda viene convertita dal modulo di parsing in un vettore, più precisamente il vettore delle occorrenze.

Il terzo modulo si occupa di classificare la domanda avendo come informazione solamente il vettore precedentemente creato.

Ora ritorniamo al primo modulo. Poiché le domande sono per loro natura brevi dobbiamo arricchirne il contenuto aggiungendo delle Feature, questo è il lavoro svolto dal Feature Adder.

\subsection{Obiettivi}
Entriamo nella fase realizzativa, la piattaforma scelta è quella di WEKA perché ci offre la possibilità di utilizzare e poter paragonare agilmente l'efficacia del classificatore con gli altri già implementati nello strumento.
Nel dettaglio gli obiettivi tecnici sono:
\begin{itemize}
	\item Creare un classificatore estendibile che rispetti l'interfaccia di WEKA;
	\item Paragonare il classificatore con algoritmi OffLine già implementati in WEKA;
	\item Studiare l'andamento del classificatore all'aumento dell'insieme di input.
\end{itemize}

\section{Pre-Processing - Feature Extraction}
Per un sistema di classificazione un punto delicato è la scelta delle feature e per tale motivo vanno scelte in modo ponderato e combatibile col dominio che viene trattato dal classificatore.

Il dominio trattato dal classificatore è composto da domande, le quali per loro propria natura sono ``compattate'' (brevi) in media in una certa finestra di lunghezza comunque molto piccola.

L'obiettivo del preprocessing è quello di arricchire le informazioni così da averne poi un beneficio diretto sul processo di classificazione immediatamente successivo.

Le feature che si vogliono introdurre hanno lo scopo di prendere in considerazione:
\begin{enumerate}
	\item L'ordine delle parole;
	\item Il valore semantico delle parole.
\end{enumerate}
La tecnica che si è adottata per soddisfare questi obiettivi è stata quella di aggiungere alla domanda nuovi elementi, ad esempio quelli ottenuti dalla giustapposizione delle parole presenti nelle domanda stessa.

\begin{figure}[htb!]
	\centering
	\includegraphics[scale=0.65]{img/WinnowClassifier-Pipeline_3.eps}
	\caption{Winnow Classifier pipeline with example}
\end{figure}
% FORSE ANCHE QUI L'IMMAGINE DI PRIMA O FORSE PRIMA SENZA IL SOTTO E ORA COL SOTTO/ESEMPI
Ad esempio se una domanda è nella forma ``What is the fire'', vengono aggiunte le parole ``What\_is'', ``is\_the'', ``the\_fire'', ottenendo quindi un risultato del genere: ``What is the fire What\_is is\_the the\_fire''.
È semplice vedere come soprattutto la prima composizione (i.e. ``What\_is'') sia di notevolmente importante nella categorizzazione delle domande.

Con la tecnica sopra descritta sono state aggiunte le segueni feature:
\begin{enumerate}
	\item Relazioni tra le parole sia a coppie che a triple;
	\item Parole ``stemmate'' (lasciando anche quelle non originali), nel dettaglio tramite lo ``Snowball Stemmer'' ed un altro rudimentale sviluppato da noi;
	\item Relazione tra la prima parola della domanda e l'ultima;
	\item Utilizzo di WordNet per la derivazione del tipo sintattico della parola ed in più la giustapposizione dei tipi sintattici per coppie e per triple. % Referenza su wordnet %
\end{enumerate}


\section{Experimental Set-Up}
Gli strumenti utilizzati per fare gli esperimenti sono:
\begin{itemize}
	\item WEKA - versione 3.5.7;
	\item SnowballStemmer - la cui interfaccia è esposta da weka;
	\item WordNet 3 - per la derivazione dei sinonimi;
	\item JFreechart 1.0.9 - per la creazione dei grafici di risultato.
\end{itemize}
La macchina di test ha le seguenti caratteristiche principali:
\begin{itemize}
	\item Processore: Intel Core 2 Duo E6600; %Oppure il tuo
	\item RAM: 2GB;
	\item S.O.: Windows XP Professional SP2. %O Vista Businnes SP1 x64
\end{itemize}

\subsection{Winnow Classifier - The Algorithm}
L'algoritmo di winnow realizzato ha la seguente architettura: ad ogni ``classe'' da classificare è associata una collezione di così detti ``esperti'', ogni esperto è relativo ad una parola, ovvero un esperto viene interpellato ogni qual volta la parola associata ad esso è presente nella domanda.
L'algoritmo quindi ha come input una domanda, per ogni parola presente nella domanda interroga il relativo esperto, se la somma dei punteggi di tutti gli esperti supera una certa soglia allora la predizione per quella determinata classe è positiva altrimenti no.
Ogni esperto quindi associa un punteggio (o peso) alla parola al quale è associato, tale punteggio viene gestito secondo l'algoritmo classico, cioè incrementandolo (raddoppiando il peso) in caso di errore su predizione negativa o decrementandolo (dimezzando il peso) in caso di errore su predizione positiva.


\subsection{WEKA Winnow Classifier}
Per poter paragonare l'efficacia del classificatore con quello dello stesso tipo di WEKA si è dovuto ``wrappare'' ben sei istanze (una per categoria da classificare) del classificatore basato su winnow di weka.

Non è stato effettuato nessun tuning particolare sul classificatore presente in WEKA. Il classificatore generato dall'unione dei classificatori base (d'ora in poi CollectionWinnow o CW) è stata necessaria perché l'algoritmo di winnow è nativamente binario e quindi non in grado di classificare più di una categoria alla volta (appartenenza o meno ad una categoria) per tale motivo si è proceduto alla costruzione di una collezione di classificatori a seguendo lo scema a cascata.

Entrando nel dettaglio della fase di training del CW i classificatori vengono ``trainati'' sempre tutti, cioè ad ogni classificatore viene dato in pasto il caso di training. Al contrario l'altro schema possibile sarebbe stato quello di non intervenire nel training se il sistema generale desse la risposta corretta ma questo renderebbe i tempi di training più lunghi e difficoltosi (motivo per il quale questa alternativa viene scartata).
si dice che è binario e che ne abbiamo fatto uno raggruppandone N uno per ogni categoria


\section{Experimental Result}
table table table 

\section{Conclusion}

\bibliography{biblio}
\bibliographystyle{plain}

\end{document}