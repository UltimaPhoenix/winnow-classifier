% DOCUMENT FORMAT %
\documentclass[twocolumn]{article}

% PACKAGE IMPORT %
\usepackage[latin1]{inputenc} %consente di mettere le accentate direttamente
\usepackage[english,italian]{babel} %sillabazione in italiano
\usepackage{cite}
\usepackage{hyperref}
%%pacchetto per l'inclusione di figure eps
\usepackage{graphicx}
\usepackage{epsfig}
\usepackage{epstopdf}

\begin{document}
\title{Question Classification and On-Line Alghoritms: Winnow Classifier}
\author{Valerio \& Fabio}
% Remove command to get current date 
\date{\today}
\maketitle

\begin{abstract}
L'articolo tratta del problema della Question Answering (QA) in particolare della Question Classification (QC).

Nel dettaglio vengono trattati i problemi che insorgono quando si vogliono realizzare algoritmi per la QC: analisi del dominio di interesse, scelta di una tipologia di algoritmo (on-line/off-line), scelta dell'algoritmo, scelta delle feature da applicare, implementazione e confronto con altri classificatori noti.%%non mi piace molto la frase riscrivere

In modo particolare l'interesse è quello di testare l'efficacia di un algoritmo on-line (Winnow) nel dominio della Question Classification,
%questo lo scrivo alla fine! farò un brevissimo riassunto, niente di particolare.
%Però tanto per anticipare quello di cui parliamo è la QC e l'implementazione fatta da noi è 
%winnow, un algoritmo on-line.
%etc~\ldots\ 
\end{abstract}

\section{Introduction}
Con l'aumento della popolarità e della diffusione del web, e conseguentemente con l'aumento 
dell'informazione testuale sul web, il processamento automatico di informazione testuale scritta in 
linguaggio naturale diviene sempre più importante.\cite{Zhalaing}. A tale fine si usano tecniche di 
Information Retrieval, che sono alla base degli attuali motori di ricerca web: quando un utente ha 
un information need, sottomette una query al motore di ricerca, che produrrà
come output un insieme di documenti che con buona probabilità dovrebbero contenere l'informazione 
necessaria all'utente.

\subsection{Question Answering}
Il Question Answering è una variazione dell'information retrieval (IR): 
mentre l'IR è orientata ai documenti, il QA ricerca specifiche informazioni all'interno dei documenti 
cercando di fornire direttamente la risposta all'information need dell'utente~\cite{WeiLi}. Ed è quindi 
un compito più difficile rispetto all'IR, poiché fornire una risposta precisa e concisa è più complesso 
di produrre un intero documento di testo probabilmente molto lungo.
Un sistema di QA è generalmente costituito da 4 moduli:
\begin{description}
	\item[Question Classifier] ha il compito di classificare la domanda in categorie prestabilite;
	\item[Search Engine] basando sulla categoria prodotta dal modulo precedente, ricerca  i documenti che hanno probabilità più alta di contenere la risposta;
	\item[Text Filter] individua le parti di testo all'interno dei documenti, che potrebbero  contenere la risposta;
	\item[Answer Extractor] deduce la risposta dalle parti di testo individuate dal modulo precedente, e le presenta in linguaggio naturale all'utente del sistema.
\end{description}
% disegno

\subsection{Question Classification}
Il processo di QC ha quindi il compito di assegnare particolari categorie alle domande, basandosi sul tipo 
di risposta che la domanda rappresenta. Per classificare le domande, o più in generale del test, 
è necessario prendere in considerazione due aspetti basilari \cite{brown}:
\begin{itemize}
	\item i tipi delle risposte, le categorie;
	\item un insieme di regole di classificazione.
\end{itemize}
 
\subsubsection{Answer Types}
Definire un proprio insieme di categorie da utilizzare nella question classification è una 
delle soluzioni, ma non sempre la migliore. È possibile utilizzare dei sistemi di categorie già usati in precedenza. 
Il riuso di tali sistemi, oltre a far risparmiare una notevole quantità di tempo, è decisamente utile per 
comparare i propri risultati con altri ottenuti in precedenza. 

I primi sistemi di question classification utilizzavano una suddivisione in un piccolo numero 
di categorie: sei o sette. Recentemente i ricercatori si sono interessati nella costruzione 
di categorie migliori: i sistemi attuali solitamente prevedono 
una divisione in 6-7 categorie a grana grossa, e una successiva suddivisione di ogni categoria in altrettante 
di dettaglio. Tra i tipi di risposte più famosi troviamo:
\begin{itemize}
	\item Xin Li e Dan Roth, che propongono una suddivisione in 50 sotto categorie e 6 macro categorie~\cite{XinLi}:	
	\begin{itemize}
		\item Abbreviation;
		\item Entity;
		\item Description;
		\item Human;
		\item Location;
		\item Numerical Value.
	\end{itemize}
	\item Webclopedia, che usa oltre 140 tipi di risposte, anche chiamati qtargets. Questi sono raggruppati in 
	8 macro categorie~\cite{gerber}:	
	\begin{enumerate}
		\item relational qtargets;
		\item abstract qtargets;
		\item semantic qtargets;
		\item syntactic qtargets;
		\item role qtargets;
		\item slot qtargets;
		\item lexical qtargets;
		\item combinations of other qtargets.
	\end{enumerate}
\end{itemize}

\subsubsection{Classification Strategies}
Esistono diverse strategie/regole di classificazione:

\paragraph{Regular expression and hand-written grammar rules} 
sono le prime tecniche utilizzate per la 
question classification, ma hanno dei grossi limiti, sebbene abbiano avuto successo \cite{brown}:
\begin{itemize}
	\item in primo luogo tali tecniche richiedono molto tempo, poiché sono scritte a mano;
	\item in secondo luogo sono poco evolvibili, con il cambiare delle categorie;
	\item se cambiamo l'insieme delle categorie, tutte le regole devono essere riscritte;
	\item infine sono molto difficili da scrivere, soprattutto quando si usano tante categorie a grana fine.
\end{itemize}
Non è un caso, infatti, che tali sistemi utilizzino meno di dieci categorie.

\paragraph{Machine Learning Algorithm}
L'algoritmo più utilizzato in questo campo è SVM, support vector machine. Un'altra architettura 
molto usata è SNoW~\cite{XinLi}. La precision di tali algoritmi, utlizzando solo le parole delle 
domande, si aggira sul 50\%. Ma si possono utilizzare molte altre feature oltre alle 
semplici parole, come ad esempio: le named entity, head chunk etc~\ldots\ 

\paragraph{Language Modeling} 
Un altro metodo, sempre probabilistico come il machine learning, è il language modeling.
Un modello di linguaggio è creato per ogni classe, a partire da tutte le domande 
appartenenti a quella classe. Dato uno di questi modelli, il nostro obiettivo è
scoprire la probabilità con cui la question sia generata da tale modello. Anche in questo caso 
si possono utilizzare altri insiemi di feature oltre alle semplici parole, come le named entity~\cite{pinto}.


\section{The starting point}
Sebbene sia possibile creare classificatori con regole euristiche costruite ad hoc~\cite{DBLP:conf/trec/Voorhees01}, tale approccio 
richiede un'enorme quantità di tempo e di noioso lavoro. Per di più un approccio troppo specifico sarebbe poco flessibile ai cambiamenti che si trovano nel dominio di interesse.
Al contrario utilizzando tecniche di machine learning è possibile costruire classificatori che abbiano alte performance e che riescano a gestire migliaia di feature. Oltretutto tale 
approccio è più flessibile e si adatta facilmente a nuove categorie~\cite{Zhang}. Ed è questo 
l'approccio che intendiamo usare per il nostro classificatore.

Le tecniche di machine learning si distinguono in due grandi categorie:
\begin{enumerate}
	\item Off-Line;
	\item On-Line.
\end{enumerate}
Le principali caratteristiche sulle quali si distinguono le due tipolodie sono: tempo di addestramento, flessibilità e conseguentemente per algoritmo.

Un classificatore off-line deve essere addestrato su un insieme di input (training set). Una volta finita la fase di addestramento, è in grado di classificare, ma non più di imparare. Nel caso si voglia far imparare al classificatore nuovi esempi, l'addestramento deve essere iniziato da zero. Questo porterebbe ad una notevole perdita di tempo se il dominio di inferenza, ma anche le categorie utilizzate, cambiassero nel tempo (rendendo il training set precedentemente utilizzato per ``costruire'' il classificatore non più coerente con lo stato attuale).

I tempi di training dei classificatori basati su tecniche di machine learning possono essere molto diversi da classificatore a classificatore; tipicamente il tempo di training di un classificatore off-line è maggiore, se confrontato con un classificatore online~\cite{Habib}.

Al contrario un algoritmo on-line impara sul campo e durante l'addestramento può comunque essere interrogato, questo consente ``all'addestratore'' di valutare in continuazione come procede il lavoro di inferenza del dominio da parte del classificatore .

All'apparenza un classificatore on-line offre più vantaggi ma come spesso accade ai ``pro'' vanno sommati dei ``contro'', che in questo caso ricadono sulle prestazioni del classificatore; un classificatore on-line è tipicamente peggiore di un classificatore off-line.


\subsection{On-Line Algorithm}
Adesso che abbiamo una conoscenza generale delle differenze tra le due classi di algoritmi dobbiamo scegliere quale delle due adottare.

Passiamo quindi all'analisi del dominio di interesse, ovvero la question classification (QC); quest'ultima appartiene ad un dominio intrinsecamente variabile, ambiguo e soprattutto dipendente dal tempo.

Il dominio della domande (cioè quello trattato dal question answering e dalla question classification) è variabile nel tempo perché i significati di una parola oltre a essere molteplici possono variare nel tempo, un caso esemplificativo ed evidente è la parola ``laico'' nella nostra lingua, dove fino a pochissimo tempo fa stava ad indicare la non appartenenza all'ecclesia mentre ora ha in pratica preso il significato di ``ateo'' e/o ``agnostico'' (una variazione di significato non indifferente).
Poiché il nostro dominio è fortemente influenzato dalle variazioni del contesto nel quale si trova e poiché l'applicabilità degli algoritmi off-line è stata studiata approfonditamente in molti lavori %inserire riferimento%
mentre non sono stati approfonditi i comportamenti che hanno gli algoritmi on-line sulla Question Classification, la scelta ricade sugli questi ultimi.

\subsection{Winnow}
Scelto di utilizzare un algoritmo on-line bisogna scegliere l'algoritmo di base per poi testarlo ed adattarlo alle nostre esigenze.

Tra gli algoritmi on-line la scelta ricade in particolare sull'algoritmo di Winnow.

L'algoritmo di Winnow è composto da un insieme di ``esperti'' non meglio precisati (che volendo possono essere veri e propri classificatori complessi) ai quali è associato un peso (inizialmente pari a \emph{1}) che vengono interpellati all'arrivo dell'oggetto da classificare.

Ogni ``esperto'' da come risultato \emph{1} o \emph{0} rispettivamente se l'oggetto appartiene alla classe oppure no.
Vengono sommati i risultati ottenuti dal prodotto del peso di ogni classificatore per la predizione corrispondente (\emph{0} oppure \emph{1}). Se il risultato finale supera la soglia (nel caso semplice pari al numero di esperti) allora l'algoritmo generale risponde in modo positivo, altrimenti in modo negativo.

Se l'algoritmo generale fallisce due sono i casi da distinguere:
\begin{enumerate}
	\item Errore su predizione positiva;
	\item Errore su predizione negativa.
\end{enumerate}
Nel primo caso vengono dimezzati i pesi degli ``esperti'' che hanno predetto \emph{1}, nel secondo invece vengono raddoppiati i pesi degli ``esperti'' che hanno predetto \emph{1}.

L'algoritmo ha molte qualità tra le quali spicca la capacita di non essere influenzato dalla presenza di molti attributi irrilevanti (``winnow è adatto in teoria per problemi con molti attributi irrilevanti''~\cite{Zhang}) e ``winnow impara linearmente con il numero di feature rilevanti, e solo logaritmicamente con il numero totale di feature. questa proprietà sembra cruciale in problemi nei quali il numero di feature potenziali è vasto ma solo poche sono rilevanti''~\cite{snow}.

\section{Winnow Project}
Il nostro classificatore ha la seguente architettura:

\begin{figure}[htb!]
	\centering
	\includegraphics[scale=0.65]{img/Winnow_Classifier_Pipeline.eps}
	\caption{Winnow Classifier pipeline}
\end{figure}
%DISEGNO CON TRE BLOCCHI
%1)	Nome: Parser
%	Input: File TREC
%	Ouput: Domanda
%2) Nome: Filters
%	Input: Domanda
%	Ouput: Vettore/Instance
%1)	Nome: Winnow
%	Input: Vettore/Instance
%	Ouput: Class

Le domande vengono prese dal file TREC \emph{train\_5500.label} disponibile sulla rete, queste vengono ``parsate'' da un modulo che le da in pasto al secondo modulo che si occupa di trasformare le domande, ora in forma testuale, in forma vettoriale per poi farle analizzare al modulo che poi si occupa di classificare.

\subsection{Obiettivi}
Entriamo nella fase realizzativa, la piattaforma scelta è quella di WEKA perché ci offre la possibilità di utilizzare e poter paragonare agilmente l'efficacia del classificatore con gli altri già implementati nello strumento.
Nel dettaglio gli obiettivi sono:
\begin{itemize}
	\item Creare un classificatore che rispetti l'interfaccia di WEKA;
	\item Paragonare il classificatore con algoritmi off-line già implementati in WEKA;
	\item Analizzare delle prestazioni relativamente a ciascuna feature introdotta;
	\item Studiare l'andamento del classificatore all'aumento dell'insieme di training.
\end{itemize}

\section{Pre-Processing - Feature Extraction}
Per un sistema di classificazione un punto delicato è la scelta delle feature e per tale motivo vanno scelte in modo ponderato e compatibile col dominio che viene trattato dal classificatore.

Il dominio trattato dal classificatore è composto da domande, le quali per loro propria natura sono ``compattate'' (brevi/compresse) in una certa finestra di lunghezza comunque molto piccola (in media).

L'obiettivo del preprocessing è quello di arricchire le informazioni così da averne poi un beneficio diretto sul processo di classificazione immediatamente successivo.

Le feature che si vogliono introdurre hanno lo scopo di prendere in considerazione:
\begin{enumerate}
	\item L'ordine delle parole;
	\item Il valore semantico delle parole.
\end{enumerate}
La tecnica che si è adottata per soddisfare questi obiettivi è stata quella di aggiungere alla domanda nuovi elementi, ad esempio quelli ottenuti dalla giustapposizione delle parole presenti nelle domanda stessa.
\begin{figure}[htb!]
	\centering
	\includegraphics[scale=0.85]{img/Filters_Detail.eps}
	\caption{Filters example}
\end{figure}
Ad esempio se una domanda è nella forma ``What is the fire'', vengono aggiunte le parole ``What\_is'', ``is\_the'', ``the\_fire'', ottenendo quindi un risultato del genere: ``What is the fire What\_is is\_the the\_fire''.
È semplice vedere come soprattutto la prima composizione (i.e. ``What\_is'') sia di notevolmente importante nella categorizzazione delle domande.

Con la tecnica sopra descritta sono state aggiunte le seguenti feature:
\begin{enumerate}
	\item Relazioni tra le parole sia a coppie che a triple;
	\item Parole ``stemmate'' (lasciando anche quelle non originali), nel dettaglio tramite lo ``Snowball Stemmer'' ed un altro rudimentale sviluppato da noi;
	\item Relazione tra la prima parola della domanda e l'ultima;
	\item Utilizzo di WordNet per la derivazione del tipo sintattico della parola ed in più la giustapposizione dei tipi sintattici per coppie e per triple. % Referenza su wordnet %
\end{enumerate}

L'ultimo filtro trasforma la domanda nel vettore delle occorrenze seguendo il modello \emph{Bag of words}.

\section{Experimental Set-Up}

\subsection{Weka Interface}
Si è scelto di sviluppare un classificatore che rispettasse l'interfaccia di \emph{WEKA} (v 3.5.7), per poter poi così comparare il lavoro da noi svolto con altri classificatori già implementati all'interno dello strumento.

\subsection{Filters}
Per aggiungere feature alla domanda sono stati utilizzati:
\begin{itemize}
	\item SnowballStemmer - la cui interfaccia è esposta da WEKA;
	\item WordNet 3 - per la derivazione dei sinonimi;
	\item Più quelli da noi creati (illustrati nella sezione precedente).
\end{itemize}

%%usato weka implementato da usare
%%snowball stemmer, wordnet 3

\subsection{Report}
Per avere una visione più intuitiva delle prestazioni del classificatore sono stati creati dei report grafici creati con \emph{JFreechart 1.0.9}.

Tale strumento consente per l'appunto di poter creare dei report riassuntivi e comparativi partendo da dati numerici.

\subsection{Winnow Classifier The Algorithm}
%Approccio Bag of Word
L'algoritmo di Winnow realizzato ha la seguente architettura: ad ogni ``classe'' da classificare è associata una collezione di così detti ``esperti'', ogni esperto è relativo ad una parola, ovvero un esperto viene interpellato ogni qual volta la parola associata ad esso è presente nella domanda.
L'algoritmo quindi ha come input una domanda, per ogni parola presente nella domanda interroga il relativo esperto, se la somma dei punteggi di tutti gli esperti supera una certa soglia allora la predizione per quella determinata classe è positiva altrimenti no.
Ogni esperto quindi associa un punteggio (o peso) alla parola al quale è associato, tale punteggio viene gestito secondo l'algoritmo classico, cioè incrementandolo (raddoppiando il peso) in caso di errore su predizione negativa o decrementandolo (dimezzando il peso) in caso di errore su predizione positiva.


\subsection{SMO Comparison}
Tra i classificatori off-line con cui effettuare la comparazione è stato scelto il classificatore SMO, integrato in WEKA.

Per poter effettuare la comparazione con un classificatore di tipo profondamente diverso (SMO è off-line al contrario del nostro) è stato necessario addestrare diverse volte il classificatore, nel dettaglio ad ogni cambiamento dell'insieme di training.

\subsection{Hardware}
La macchina di test ha le seguenti caratteristiche principali:
\begin{itemize}
	\item Processore: Intel Core 2 Duo T7500; %Oppure il tuo
	\item RAM: 3GB;
	\item S.O.: Windows Vista Business x64 SP1.
\end{itemize}

\section{Experimental Result}
table table table 

\section{Conclusion}
%BOZZA CONCETTI%
Come visibile dai grafici l'algoritmo di Winnow soffre di una oscillazione, caratteristica propria dell'algoritmo. L'ampiezza dell'oscillazione dipende dai parametri interni dell'algoritmo.

Si può dire che l'algoritmo di Winnow non tradisce le aspettative, pur avendo prestazioni nettamente inferiori ad un classificatore off-line (e.g. SMO).

Considerando che le feature introdotte sono semplici e che il tuning non è stato fatto in modo minuzioso, i margini di miglioramento di certo ci sono.

\bibliography{biblio}
\bibliographystyle{plain}

\end{document}