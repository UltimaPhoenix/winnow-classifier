% DOCUMENT FORMAT %
\documentclass[twocolumn]{article}

% PACKAGE IMPORT %
\usepackage[latin1]{inputenc} %consente di mettere le accentate direttamente
\usepackage[italian]{babel} %sillabazione in italiano
\usepackage{cite}
\usepackage{hyperref}

\begin{document}
\title{Question Classification and On-Line Alghoritms: Winnow Classifier}
\author{valerio \& fabio}
% Remove command to get current date 
\date{\today}
\maketitle

\begin{abstract}
questo lo scrivo alla fine! farò un brevissimo riassunto, niente di particolare.
Però tanto per anticipare quello di cui parliamo è la QC e l'implementazione fatta da noi è 
winnow, un algoritmo on-line.
etc...
\end{abstract}

\section{Introduction}
Con l'aumento della popolarità e della diffusione del web, e conseguentemente con l'aumento 
dell'informazione testuale sul web, il processamento automatico di informazione testuale scritta in 
linguaggio naturale diviene sempre più importante.\cite{Zhalaing}. A tale fine si usano tecniche di 
Information Retrieval, che sono alla base degli attuali motori di ricerca web: quando un utente ha 
un information need, sottomette una query al motore di ricerca, che produrrà
come output un insieme di documenti che con buona probabilit\'a dovrebbero contenere l'informazione 
necessaria all'utente.

\subsection{Question Answering}
Il Question Answering è una variazione dell'information retrieval (IR): 
mentre l'IR è orientata ai documenti, il QA ricerca specifiche informazioni all'interno dei documenti 
cercando di fornire direttamente la risposta all'information need dell'utente \cite{WeiLi}. Ed è quindi 
un compito più difficile rispetto all'IR, poiché fornire una risposta precisa e concisa è più complesso 
di produrre un intero documento di testo probabilmente molto lungo.
Un sistema di QA è generalmente costituito da 4 moduli:
\begin{description}
	\item[Question Classifier] ha il compito di classificare la domanda in categorie 
	prestabilite;
	\item[Search Engine] basando sulla categoria prodotta dal modulo precedente, ricerca 
	i documenti che hanno probabilità più alta di contenere la risposta;
	\item[Text Filter] individua le parti di testo all'interno dei documenti, che potrebbero 
	contenere la risposta;
	\item[Answer Extractor] deduce la risposta dalle parti di testo individuate dal modulo 
	precedente, e le presenta in linguaggio naturale all'utente del sistema.
\end{description}
%disegno%

\subsection{Question Classification}
Il processo di QC ha quindi il compito di assegnare particolari categorie alle domande, basandosi sul tipo 
di risposta che la domanda rappresenta. Per classificare le domande, o più in generale del test, 
è necessario prendere in considerazione due aspetti basilari \cite{brown}:
\begin{itemize}
	\item i tipi delle risposte, le categorie;
	\item un insieme di regole di classificazione.
\end{itemize}
 
\subsubsection{Answer Types}
Definire un proprio insieme di categorie da utilizzare nella question classification è una 
delle soluzioni, ma non sempre la migliore. È possibile utilizzare dei sistemi di categorie già usati in precedenza. 
Il riuso di tali sistemi, oltre a far risparmiare una notevole quantità di tempo, è decisamente utile per 
comparare i propri risultati con altri ottenuti in precedenza. 

I primi sistemi di question classification utilizzavano una suddivisione in un piccolo numero 
di categorie: sei o sette. Recentemente i ricercatori si sono interessati nella costruzione 
di categorie migliori: i sistemi attuali solitamente prevedono 
una divisione in 6-7 categorie a grana grossa, e una successiva suddivisione di ogni categoria in altrettante 
di dettaglio. Tra i tipi di risposte più famoss troviamo:
\begin{itemize}
	\item Xin Li e Dan Roth, che propongono una suddivisione in 50 sotto categorie e 6 macro categorie \cite{XinLi}:	
	\begin{itemize}
		\item Abbreviation;
		\item Entity;
		\item Description;
		\item Human;
		\item Location;
		\item Numerical Value.
	\end{itemize}
	\item Webclopedia, che usa oltre 140 tipi di risposte, anche chiamati qtargets. Questi sono raggruppati in 
	8 macro categorie \cite{gerber}:	
	\begin{enumerate}
		\item relational qtargets;
		\item abstract qtargets;
		\item semantic qtargets;
		\item syntactic qtargets;
		\item role qtargets;
		\item slot qtargets;
		\item lexical qtargets;
		\item combinations of other qtargets.
	\end{enumerate}
\end{itemize}

\subsubsection{Classification Strategies}
Esistono diverse strategie/regole di classificazione:

\paragraph{Regular expression and hand-written grammar rules} 
sono le prime tecniche utilizzate per la 
question classification, ma hanno dei grossi limiti, sebbene abbiano avuto successo \cite{brown}:
\begin{itemize}
	\item in primo luogo tali tecniche richiedono molto tempo, poich\'e sono scritte a mano;
	\item in secondo luogo sono poco evolvibili, con il cambiare delle categorie;
	\item se cambiamo l'insieme delle categorie, tutte le regole devono essere riscritte;
	\item infine sono molto difficili da scrivere, soprattutto quando si usano tante categorie a grana fine.
\end{itemize}
Non è un caso, infatti, che tali sistemi utilizzino meno di dieci categorie.

\paragraph{Machine Learning Algorithm}
L'algoritmo più utilizzato in questo campo è SVM, support vector machine. Un'altra architettura 
molto usata è SNoW \cite{XinLi}. La precision di tali algoritmi, utlizzando solo le parole delle 
domande, si aggira sul 50\%. Ma si possono utilizzare molte altre feature oltre alle 
semplici parole, come ad esempio: le named entity, head chunk etc.

\paragraph{Language Modleling} 
Un altro metodo, sempre probabilistico come il machine learning, è il language modeling.
Un modello di linguaggio è creato per ogni classe, a partire da tutte le domande 
appartenenti a quella classe. Dato uno di questi modelli, il nostro obiettivo è
scoprire la probabilità con cui la question sia generata da tale modello. Anche in questo caso 
si possono utilizzare altri insiemi di feature oltre alle semplici parole, come le named entity \cite{pinto}.


\section{Our Scope: Machine Learning}
Sebbene sia possibile create classificatori con regole euristiche costruite ad hoc, tale approccio 
richiede un'enorme quantità di tempo e di noioso lavoro. Per di più un approccio troppo specifico sarebbe poco flessibile ai cambiamenti che si trovano nel dominio di interesse.
Utilizzando tecniche di machine learning è al contrario è possibile costruire classificatori che abbiano alte performance e che riescano a gestire migliaia di feature. Oltretutto tale 
approccio è più flessibile e si adatta facilmente a nuove categorie \cite{Zhang}. Ed è questo 
l'approccio che intendiamo usare per il nostro classificatore.
I classificatori si disinguono in due grosse macrocategorie:
\begin{enumerate}
	\item OffLine;
	\item OnLine.
\end{enumerate}
le due categorie si distinguono soprattuto per prestazioni, tempo di addestramento, flessibilità e conseguentemente per algoritmo.

Un classificatore OffLine deve essere addestrato da un insieme di input (insieme di training) e solo dopo questa operazione può essere utilizzato per classificare ma non può più in essere riaddestrato se non ricompiendo un addestramento completo. Al contrario un algoritmo OnLine, per così dire, impara sul campo e durante l'addestramento può comunque essere interrogato, questo consente all'addestratore di valutare in continuazione come sta procedendo il lavoro di inferenza del dominio da parte del calssificatore.
All'apparenza un classificatore OnLine offre pi\'u vantaggi ma come spesso accade ai ``pro'' vanno sommati dei ``contro'', che in questo caso ricadono sulle prestazioni del classificatore; un classificatore OnLine \'e tipicamente peggiore di un classificatore OffLine.


\subsection{On-Line Algorithm}
Adesso che abbiamo una conoscenza generale delle differenze tra le due classi di algoritmi dobbiamo scegliere quale delle due adottare. Passiamo quindi all'analisi del nostro dominio di interesse, cioè la question classification; quest'ultima appartiene ad un dominio intrinsecamente variabile, ambiguo e soprattuto variabile nel tempo. La QA è variabile nel tempo perché i significati di una parola sono molteplici e possono variare nel tempo, un caso esemplificativo ed evidente è la parola ``laico'' nella nostra lingua dove fino a pochisimo tempo fa stava ad indicare la non appartenenza all'ecclesia mentre ora ha in pratica preso il significato di ``ateo'' e/o ``agnostico'' (una variazione di significato non indifferente).
Poich\'e il nostro dominio è fortemente influenzato dalle variazioni del constesto nel quale si trova e poiché l'applicabilita' degli algoritmi OffLine è stata studiata approfinditamente in molti lavori %inserire riferimento%
mentre non sono stati approfonditi i comportamenti che hanno gli algoritmi OnLine sul dominio della Question Classification, la scelta ricade sugli questi ultimi.

\subsection{Winnow}
Avendo scelto di utiilizzare un algoritmo OnLine dobbiamo decidere quale algoritmo di base scegliere per poi testarlo ed adattarlo alle nostre esigenze.
%per ora chiudo veloce ma qui referenze facili%
Tra gli algoritmi OnLine la scelta ricade in particolare sull'algoritmo di Winnow.
Questo algoritmo ha delle qualita tra le quali spicca la capacita di non essere influenzato dalla presenza di molti attributi irrilevanti (``winnow \'e adatto in teoria per problemi con molti attributi irrilevanti'' \cite{Zhang}) e 
``winnow impara linearmente con il numero di feature rilevanti, e solo logaritmicamente con il numero totale di feature. questa proprietà sembra cruciale in problemi nei quali il numero di feature potenziali è vasto 
ma solo poche sono rilevanti'' \cite{snow}.

\section{Winnow Project}
Il progetto di un nostro classificatore avrà la seguente architettura:
%DISEGNO CON TRE BLOCCHI
%1)	Nome: Parsing
%	Input: Domanda
%	Ouput: Weka Instance
%1)	Nome: Feature Adder
%	Input: Vettore/Instance
%	Ouput: Vettore/Instance più grande
%1)	Nome: Winnow Classifier
%	Input: Vettore/Instance
%	Ouput: Class


\subsection{Obiettivi}
Noi vogliamo paragonarlo con quello di weka 

\section{Pre-Processing - Feature Extraction}
Una volta scelto l'algoritmo passiamo alla realizzazione dello stesso scegliendo anche le feature da aggiungere per aumentare le prestazioni del nostro classificatore.
Poiché il nostro scopo è 

\section{Experimental Set-Up}

\section{Experimental Result}
table table table 

\section{Conclusion}

\bibliography{tesina}
\bibliographystyle{plain}

\end{document}